#!/bin/bash

cd ~/Documents/git-repos/remote-github/data-extract-from-website

# Unset globbing
set -f

# Now readarray delimits with newlines
IFS='
'

# No case sensitivity for string matching
shopt -s nocasematch

readarray PRODUCTS < ./products-to-look-for
readarray EMAILS < ./emails

touch fetchedPage
rm -rf fetchedPage

echo "Downloading webpage: http://www.pickapart.ca/"
wget -O fetchedPage "http://www.pickapart.ca/"

DATE_RANGE=$(command grep -Eo '[[:alpha:]]{3} [[:digit:]]{2}, [[:digit:]]{4} - [[:alpha:]]{3} [[:digit:]]{2}, [[:digit:]]{4}' fetchedPage)

# -e lets the \n act as a newline character
echo -e "Pick a Part has the following on sale from $DATE_RANGE:\n" > foundProducts



# At the end of all td tags start a new line.
sed -i "s@</td>@</td>\n@g" fetchedPage

# Open fetchedPage
declare -a ARRAY
exec 10<&0
fileName="fetchedPage"
exec < $fileName
let count=0

# Each line gets stored in an array.
while read LINE; do
  ARRAY[$count]=$LINE
  ((count++))
done

exec 0<&10 10<&-

# Used to find the lines we need.
regex="<td align='center' valign='top'>[[:print:]]*</td>"

touch tdtags
rm -rf tdtags
touch tdtags

ELEMENTS=${#ARRAY[@]}
firstLine=0


# make tdtags file that contains only the useful information.
for((i=0;i<$ELEMENTS;i++)); do
  if [[ ${ARRAY[${i}]} =~ $regex ]] ; then
    if [[ $firstLine<1 ]]; then
      echo ${BASH_REMATCH[0]} > tdtags
      let firstLine=$firstLine+1
    else
      echo ${BASH_REMATCH[0]} >> tdtags
    fi
  fi
done

# Remove all unwanted values from tdtags
# This generates a file tdtags that contains the item on one line, followed by
# the price on the second line.
# remove "<td align='center' valign='top'>" from each line
sed -i "s@<td align='center' valign='top'>@@g" tdtags
# remove </td> tags
sed -i "s@</td>@@g" tdtags
# removes the <br> tag and replaces it with " - ". That way the product name and
# price are separated by a " - "
sed -i "s@<br>@ - @g" tdtags

# Put the fetched items from tdtags into an array
readarray FETCHED_ITEMS < ./tdtags
NUM_FOUND=0

echo "Searching webpage for items of interest:"
for PRODUCT in "${PRODUCTS[@]}"
do
  # Skip comments when parsing
  [[ ${PRODUCT:0:1} == "#" ]] && continue
  # Skip empty lines when parsing
  [[ ${PRODUCT:1:1} == "" ]] && continue

  # Remove trailing newline from the name
  PRODUCT=$(echo ${PRODUCT} | tr -d '\n')

  # See if PRODUCT is found on the webpage
  # If it is, print it to the console, and append it to foundProducts file.
  for FETCHED_ITEM in "${FETCHED_ITEMS[@]}"
  do
    if [[ $FETCHED_ITEM =~ $PRODUCT ]]; then
      echo -n "- $FETCHED_ITEM" >> foundProducts
      echo -n "Found:  $FETCHED_ITEM"
      ((NUM_FOUND++))
    fi
  done

done

#remove duplicate entries in foundProducts
awk '!a[$0]++' foundProducts > tmp && mv tmp foundProducts

COUNT=0
echo "Sending emails..."
for EMAIL in "${EMAILS[@]}"
do
  # Used to echo if the line is commented
  COUNT=$((COUNT + 1))
  # Skip comments when parsing
  # Also if it is commented print to the log and console that it is commented.
  [[ ${EMAIL:0:1} == "#" ]] && echo "Line #$COUNT is Commented"  && continue
  # Skip empty lines when parsing
  [[ ${EMAIL:1:1} == "" ]] && continue

  # If more than one item was found, send an email saying that x was found
  if [[ $NUM_FOUND > 0 ]]; then
    mutt -s "Pick a Part Alert: $DATE_RANGE" $EMAIL < foundProducts

    # otherwise, Send an email saying that there is no items.
  else
    echo "Pick a Part has nothing on sale this week ($DATE_RANGE) that you are looking for." | mutt -s "Pick a Part Alert: $DATE_RANGE" $EMAIL
  fi
  # -n removes trailing newlines
  echo -n "Sent to $EMAIL"
done

# Cleanup
echo "cleanup..."
rm -rf fetchedPage
rm -rf awk1
rm -rf awk2
rm -rf foundProducts
rm -rf tdtags

unset IFS
set +f

